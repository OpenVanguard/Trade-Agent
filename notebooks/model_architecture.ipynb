{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da5dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')  # so Python can find dqn_model.py\n",
    "\n",
    "from dqn_model import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a30ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "GPU memory: 8.6 GB\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "state_dim = 59  # change to your actual state_dim\n",
    "action_dim = 3\n",
    "agent = DQNAgent(state_dim=state_dim, action_dim=action_dim, use_gpu=True)  # disable GPU if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4564f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: torch in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torchviz) (2.7.1+cu118)\n",
      "Requirement already satisfied: graphviz in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torchviz) (0.21)\n",
      "Requirement already satisfied: filelock in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torch->torchviz) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torch->torchviz) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torch->torchviz) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torch->torchviz) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torch->torchviz) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from torch->torchviz) (2025.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from sympy>=1.13.3->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\virat\\projects\\stock-price-analysis-rl\\stock_rl_env\\lib\\site-packages (from jinja2->torch->torchviz) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\images\\\\dqn_q_network.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "%pip install torchviz\n",
    "from torchviz import make_dot\n",
    "\n",
    "dummy_input = torch.randn(1, agent.state_dim).to(agent.device)\n",
    "output = agent.q_network(dummy_input)\n",
    "\n",
    "# Visualize the computation graph\n",
    "dot = make_dot(output, params=dict(agent.q_network.named_parameters()))\n",
    "dot.format = 'png'\n",
    "dot.render('../images/dqn_q_network', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630934c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001CE5FB4BBB0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/72/25/973bd6128381951b23cdcd8a9870c6dcfc5606cb864df8eabd82e529f9c1/torchinfo-1.8.0-py3-none-any.whl.metadata\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001CE5FB4BE50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/72/25/973bd6128381951b23cdcd8a9870c6dcfc5606cb864df8eabd82e529f9c1/torchinfo-1.8.0-py3-none-any.whl.metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [1, 3]                    --\n",
       "├─Linear: 1-1                            [1, 1024]                 61,440\n",
       "├─LayerNorm: 1-2                         [1, 1024]                 2,048\n",
       "├─ReLU: 1-3                              [1, 1024]                 --\n",
       "├─Dropout: 1-4                           [1, 1024]                 --\n",
       "├─Linear: 1-5                            [1, 512]                  524,800\n",
       "├─LayerNorm: 1-6                         [1, 512]                  1,024\n",
       "├─ReLU: 1-7                              [1, 512]                  --\n",
       "├─Dropout: 1-8                           [1, 512]                  --\n",
       "├─Linear: 1-9                            [1, 256]                  131,328\n",
       "├─LayerNorm: 1-10                        [1, 256]                  512\n",
       "├─ReLU: 1-11                             [1, 256]                  --\n",
       "├─Dropout: 1-12                          [1, 256]                  --\n",
       "├─Linear: 1-13                           [1, 128]                  32,896\n",
       "├─LayerNorm: 1-14                        [1, 128]                  256\n",
       "├─ReLU: 1-15                             [1, 128]                  --\n",
       "├─Dropout: 1-16                          [1, 128]                  --\n",
       "├─Linear: 1-17                           [1, 64]                   8,256\n",
       "├─ReLU: 1-18                             [1, 64]                   --\n",
       "├─Linear: 1-19                           [1, 3]                    195\n",
       "==========================================================================================\n",
       "Total params: 762,755\n",
       "Trainable params: 762,755\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.76\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 3.05\n",
       "Estimated Total Size (MB): 3.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(agent.q_network, input_size=(1, agent.state_dim), device=str(agent.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80dd23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\images\\\\dqn_q_network_compgraph.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "dummy = torch.randn(1, agent.state_dim).to(agent.device)\n",
    "out = agent.q_network(dummy)\n",
    "dot = make_dot(out, params=dict(agent.q_network.named_parameters()))\n",
    "dot.render('../images/dqn_q_network_compgraph', format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d74d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_diagram.py\n",
    "# Render a neuron-level MLP diagram with Graphviz, sampling large layers for readability.\n",
    "\n",
    "from graphviz import Digraph\n",
    "import math\n",
    "from typing import List, Optional\n",
    "\n",
    "def sample_indices(n: int, k: int) -> List[int]:\n",
    "    \"\"\"Evenly sample k indices from range(n), preserving first/last for edges.\"\"\"\n",
    "    if k >= n:\n",
    "        return list(range(n))\n",
    "    # Even spacing across [0, n-1]\n",
    "    return sorted(set([0, n-1] + [round(i*(n-1)/(k-1)) for i in range(k)]))[:k]\n",
    "\n",
    "def format_layer_label(name: str, size: int, extras: Optional[str] = None) -> str:\n",
    "    lab = f\"{name} ({size})\"\n",
    "    if extras:\n",
    "        lab += f\"\\\\n{extras}\"\n",
    "    return lab\n",
    "\n",
    "def draw_mlp_neurons(\n",
    "    layer_sizes: List[int],\n",
    "    layer_names: Optional[List[str]] = None,\n",
    "    layer_extras: Optional[List[Optional[str]]] = None,\n",
    "    max_neurons_per_layer: int = 32,\n",
    "    filename: str = \"dqn_neuron_diagram\",\n",
    "    engine: str = \"dot\",\n",
    "    rankdir: str = \"LR\",\n",
    "    node_size: str = \"0.3\",   # inches\n",
    "    node_color: str = \"lightgray\",\n",
    "    edge_color: str = \"gray50\",\n",
    "    dpi: int = 150\n",
    "):\n",
    "    \"\"\"\n",
    "    layer_sizes: e.g., [state_dim, 1024, 512, 256, 128, 64, action_dim]\n",
    "    layer_names: e.g., [\"Input\", \"Dense1\", \"Dense2\", \"Dense3\", \"Dense4\", \"Dense5\", \"Output\"]\n",
    "    layer_extras: e.g., [None, \"LayerNorm+ReLU+Dropout(0.2)\", \"LayerNorm+ReLU+Dropout(0.15)\", ... , \"Linear\"]\n",
    "    \"\"\"\n",
    "    assert len(layer_sizes) >= 2, \"Need at least input and output layers\"\n",
    "    if layer_names is None:\n",
    "        layer_names = [f\"Layer {i}\" for i in range(len(layer_sizes))]\n",
    "    if layer_extras is None:\n",
    "        layer_extras = [None] * len(layer_sizes)\n",
    "    assert len(layer_names) == len(layer_sizes)\n",
    "    assert len(layer_extras) == len(layer_sizes)\n",
    "\n",
    "    # Prepare neuron indices per layer (sampling if large)\n",
    "    layer_index_maps = []\n",
    "    for sz in layer_sizes:\n",
    "        idxs = sample_indices(sz, max_neurons_per_layer)\n",
    "        layer_index_maps.append(idxs)\n",
    "\n",
    "    g = Digraph(filename=filename, format=\"png\", engine=engine)\n",
    "    g.attr(rankdir=rankdir)\n",
    "    g.attr(\"graph\", dpi=str(dpi), splines=\"spline\", pad=\"0.2\", nodesep=\"0.2\", ranksep=\"1.2\")\n",
    "    g.attr(\"node\", shape=\"circle\", width=node_size, height=node_size, fixedsize=\"true\",\n",
    "           style=\"filled\", fillcolor=node_color, color=\"black\", penwidth=\"1\")\n",
    "    g.attr(\"edge\", color=edge_color, arrowsize=\"0.6\", penwidth=\"0.8\")\n",
    "\n",
    "    # Create subgraphs per layer (cluster to keep nodes grouped and aligned)\n",
    "    layer_node_ids: List[List[str]] = []\n",
    "    for li, (name, sz, extras, idxs) in enumerate(zip(layer_names, layer_sizes, layer_extras, layer_index_maps)):\n",
    "        with g.subgraph(name=f\"cluster_{li}\") as s:\n",
    "            s.attr(label=format_layer_label(name, sz, extras), labelloc=\"t\", labeljust=\"c\",\n",
    "                   color=\"gray70\", style=\"rounded\")\n",
    "            s.attr(rank=\"same\")\n",
    "            nodes_this_layer = []\n",
    "            for j, orig_idx in enumerate(idxs):\n",
    "                nid = f\"L{li}_N{orig_idx}\"\n",
    "                s.node(nid, label=\"\")\n",
    "                nodes_this_layer.append(nid)\n",
    "            layer_node_ids.append(nodes_this_layer)\n",
    "\n",
    "            # Invisible chain to enforce vertical ordering within the layer (keeps neat stacks)\n",
    "            for a, b in zip(nodes_this_layer, nodes_this_layer[1:]):\n",
    "                s.edge(a, b, style=\"invis\")\n",
    "\n",
    "    # Connect layers (fully connect sampled neurons between adjacent layers)\n",
    "    for li in range(len(layer_sizes) - 1):\n",
    "        left_nodes = layer_node_ids[li]\n",
    "        right_nodes = layer_node_ids[li + 1]\n",
    "        # Dense bipartite edges can be heavy; consider downsampling further if needed\n",
    "        for ln in left_nodes:\n",
    "            for rn in right_nodes:\n",
    "                g.edge(ln, rn)\n",
    "\n",
    "    # Render to file\n",
    "    outpath = g.render(cleanup=True)\n",
    "    print(f\"Saved diagram to: {outpath} (and source: {filename}.gv)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example for your DQNAgent MLP:\n",
    "    # Replace these with real values:\n",
    "    state_dim = 59  # e.g., your actual state_dim\n",
    "    action_dim = 3   # e.g., your actual action_dim\n",
    "\n",
    "    layer_sizes = [state_dim, 1024, 512, 256, 128, 64, action_dim]\n",
    "    layer_names = [\n",
    "        \"Input\",\n",
    "        \"Dense 1024\",\n",
    "        \"Dense 512\",\n",
    "        \"Dense 256\",\n",
    "        \"Dense 128\",\n",
    "        \"Dense 64\",\n",
    "        \"Output\"\n",
    "    ]\n",
    "    # Extras reflect your architecture blocks\n",
    "    layer_extras = [\n",
    "        None,\n",
    "        \"LayerNorm+ReLU+Dropout(0.2)\",\n",
    "        \"LayerNorm+ReLU+Dropout(0.15)\",\n",
    "        \"LayerNorm+ReLU+Dropout(0.1)\",\n",
    "        \"LayerNorm+ReLU+Dropout(0.05)\",\n",
    "        \"ReLU\",\n",
    "        \"Linear (Q-values)\"\n",
    "    ]\n",
    "\n",
    "    draw_mlp_neurons(\n",
    "        layer_sizes=layer_sizes,\n",
    "        layer_names=layer_names,\n",
    "        layer_extras=layer_extras,\n",
    "        max_neurons_per_layer=32,   # try 24 or 16 for lighter graphs\n",
    "        filename=\"dqn_neuron_diagram\",\n",
    "        rankdir=\"LR\",\n",
    "        node_size=\"0.28\",\n",
    "        dpi=150\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69885bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "Source.from_file(\"dqn_neuron_diagram.gv\").render(format=\"png\", view=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
